---
title: "tg-matcher 2: Preliminary analysis"
output:
  html_document:
    toc: true
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = F, message = F)
knitr::opts_chunk$set(dev = "png", dev.args = list(type = "cairo-png"))
options(knitr.table.format = "html")
knitr::opts_chunk$set(echo = F)
library(tidyverse)
library(viridis)
library(here)
library(ggthemes)
library(knitr)
library(ggtext)
library(ggimage)
library(jsonlite)
theme_set(theme_bw())

dat_loc <- "data/tgmatchercalibration-trials.csv"
model_location <- "code/models"

images <- "experiments/expt1/assets/images"
```


# Boring stuff
## Read in data

```{r}
raw <- read_csv(here(dat_loc)) |>
  select(-proliferate.condition) |>
  filter(!is.na(response))

free_response <- raw |>
  filter(is.na(correct_tangram)) |>
  select(workerid, stimulus, response, rt)

good_stuff <- raw |>
  filter(!is.na(correct_tangram)) |>
  select(
    workerid, button_rt, correct, correct_tangram,
    gameId, selected, text, trial_index
  ) |>
  mutate(workerid = as.factor(workerid)) |>
  mutate(rt_sec = button_rt / 1000,
    correct = as.numeric(correct)
  ) |>
  group_by(workerid) |>
  mutate(trial_order = row_number()) |>
  ungroup()
```

```{r}
good_stuff |> select(text) |> unique()
good_stuff |> unique()
```


##  Bonus
```{r, eval=F}
worker <- read_csv(here("data/tgmatchercalibration-workerids.csv")) |> mutate(workerid = as.factor(workerid))

bonuses <- good_stuff |>
  group_by(workerid) |>
  summarize(bonus = round(sum(correct) * .05, 2)) |>
  left_join(worker) |>
  select(prolific_participant_id, bonus) |>
  write_csv(here("bonus.csv"))

cost <- bonuses |>
  mutate(cost = bonus * 4 / 3) |>
  summarize(s = sum(cost))

#153.4+ 2.5
```

## Timing

This is clock time over the whole experiment (paying attention or not)

```{r}
total_rt <- raw |>
  group_by(workerid) |>
  summarize(m = max(time_elapsed) / 1000 / 60)
# want to know about outliers... since some participants might have paused at some point

ggplot(total_rt, aes(x = m)) +
  geom_histogram() +
  labs(x = "Total elapsed time in minutes")
```

How long are individual trials taking? 
```{r}
# good_stuff |> group_by(workerid) |> mutate(winsor_time=ifelse(rt_sec>60, 60, rt_sec)) |> summarize(total_trial = sum(rt_sec)/60) |>
# ggplot(aes(x=total_trial))+geom_histogram()
good_stuff |>
  ggplot(aes(x = trial_order, y = rt_sec)) +
  labs(y = "Time in seconds", x = "Trial") +
  geom_point(alpha = .1)
```

if we exclude the > than 1 minute ones (as plausible got distracted doing other things), mean rts: 


```{r}
good_stuff |>
  group_by(workerid) |>
  filter(rt_sec < 60) |>
  summarize(mean_time = mean(rt_sec)) |>
  ggplot(aes(x = mean_time)) +
  geom_histogram() +
  labs(x = "Mean per-participant response time in seconds")
```

So, 10ish seconds per trial generally. 

# Accuracy

```{r}
acc_by_participant <- good_stuff |>
  group_by(workerid) |>
  summarize(acc = sum(correct) / n())

```

No random guessers, yay!

```{r}
ggplot(acc_by_participant, aes(x = "By participant", y = acc)) +
  geom_jitter(height = 0, width = .4) +
  coord_cartesian(ylim = c(0, 1), xlim = c(.5, 1.5), expand = F) +
  geom_hline(yintercept = 1 / 12, linetype = "dashed", color = "blue") +
  stat_summary(data.fun = "mean_cl_boot", color = "blue") +
  labs(x = "", y = "Percent correct")
```
# Calibration

```{r}

ParseJSONColumn <- function(x) {
 str_replace_all(x,"'",'"') %>% 
    str_replace_all( 'Don"t know', "Don't know") %>% 
    str_replace_all( 'don"t', "don't") |> 
    str_replace_all("None", '"NA"') |> 
    str_replace_all('"SAFE"', "'SAFE'") |> 
    str_replace_all('he"s', "he's") |> 
    str_replace_all('doesn"t', "doesn't") |>
        str_replace_all('hasn"t', "hasn't") |> 
    str_replace_all('it"s', "it's") |> 
        str_replace_all('It"s', "It's") |> 

    str_replace_all('X" shaped', "'X' shaped") |> 
    str_replace_all('"missing', 'missing') |> 
    str_replace_all('"flying"', "flying") |> 
    str_replace_all('"skating"', "skating") |> 
        str_replace_all('"partially sitting"', "partially sitting") |> 
    str_replace_all('"kneeling" and ', "kneeling and ") |> 
    str_replace_all('"partially kneeling"', "partially kneeling") |> 
    str_replace_all('and "bunny"', "and bunny") |> 
    str_replace_all('"square"', "square") |> 
    str_replace_all('heads"', "heads") |> 
    str_replace_all('"italy"', "italy") |> 
        str_replace_all('they"re', "they're") |> 

    str_replace_all('"but why"', "'but why'") |> 
    fromJSON(flatten = T)
}
labels <- read_csv(here("expt_prep_code/labelled.csv")) |> mutate(text=str_replace_all(text, "'", "") |> str_replace_all('"', "")) |> group_by(tangram, gameId, trialNum, repNum, value, grouping) |> summarize(text=str_c(text, collapse=" "))


ready <- good_stuff |> mutate(new=map(text, ParseJSONColumn)) |> select(-text) |>  unnest(new) |> mutate(text=text |> str_replace_all("'", ""), tangram=correct_tangram) |> group_by(workerid, correct, tangram, gameId, trial_order) |> summarize(text=str_c(text, collapse=" ")) 

good <- ready |> left_join(labels) 

good |> select(workerid, correct, tangram, gameId, trialNum, repNum, value, grouping) |> write_csv(here("calibration_results.csv"))

```

```{r}

summ <- good |> group_by(grouping) |> summarize(human_acc=mean(correct), value=mean(value))

for_corr <- good |> group_by(text, value, tangram, grouping) |> summarize(human_acc=mean(correct), human_n=n())

for_corr|> ggplot(aes(y=human_acc, x=value))+geom_point(aes(color=grouping))+geom_line(data=summ, color="black")+geom_smooth(method="lm")+geom_smooth()+
  theme(legend.position="none")+labs(x="Model predicted probability", y="Human accuracy")


for_corr|> ggplot(aes(x=human_acc, y=value))+geom_point(aes(color=grouping))+geom_line(data=summ, color="black")+geom_smooth(method="lm")+
  theme(legend.position="none")+labs(y="Model predicted probability", x="Human accuracy")


cor.test(for_corr$value, for_corr$human_acc)


for_corr|> ggplot(aes(y=human_acc, x=value, color=tangram))+geom_point(aes(color=tangram))+geom_smooth(method="lm", se=F)+
  theme(legend.position="none")+labs(x="Model predicted probability", y="Human accuracy")

```